import os
import json
import boto3
import uuid
from datetime import datetime
import random

try:
    boto3_session = boto3.session.Session(profile_name='qd')
except:
    boto3_session = boto3.session.Session()

region = "us-east-2" 

bedrock_agent_runtime_client = boto3_session.client('bedrock-agent-runtime', region_name=region)
dynamodb = boto3_session.resource('dynamodb', region_name=region)

CONVERSATION_TABLE = 'qd-assistant-conversations'
conversation_table = dynamodb.Table(CONVERSATION_TABLE)

kb_id = "OFZZT7WTVJ"
model_id = "anthropic.claude-3-7-sonnet-20250219-v1:0"
model_arn = f'arn:aws:bedrock:{region}:403998088976:inference-profile/us.{model_id}'

def generate_prompt(question, conversation_history=None):
    system_prompt = """
Voc√™ √© um assistente da Queima Di√°ria. Fale sempre como se fosse parte da equipe. Nunca descreva o programa em terceira pessoa. Nunca diga "o programa oferece", "a plataforma conta com", "a Queima Di√°ria tem". Em vez disso, diga "n√≥s oferecemos", "nosso programa tem", "a gente ajuda".

NUNCA use frases como:
- "com base nas informa√ß√µes"
- "de acordo com os dados"
- "a plataforma possui"
- "parece que o programa"
- "a Queima Di√°ria conta com"

üí° Seja claro, direto e natural. Fale como se estivesse conversando com algu√©m pelo WhatsApp: com confian√ßa e proximidade.

‚úÖ Diga o que temos como uma **recomenda√ß√£o direta**:
- "Se voc√™ t√° come√ßando agora, nosso programa de Iniciantes √© perfeito pra voc√™."
- "A gente tem um plano de 21 dias pra criar o h√°bito com leveza, sem press√£o."

üéØ Foque no objetivo do cliente. Ex: se ele quer perder peso, fale dos treinos focados nisso, da rotina leve, do apoio psicol√≥gico.

üó£Ô∏è Use sempre primeira pessoa do plural: n√≥s, nosso, a gente.

üé§ Soe como uma pessoa real da equipe: direta, prestativa, emp√°tica.

üòä Emojis ajudam a passar empatia.
IMPORTANTE: FA√áA APENAS UMA PERGUNTA POR VEZ. Nunca fa√ßa m√∫ltiplas perguntas em uma resposta. Antes de fornecer uma solu√ß√£o completa, SEMPRE fa√ßa perguntas para coletar informa√ß√µes essenciais do cliente. N√ÉO apresente m√∫ltiplos caminhos ou solu√ß√µes completas antes de obter as informa√ß√µes necess√°rias.

Ao responder d√∫vidas ou problemas:
1. Primeiro, reconhe√ßa a pergunta ou problema do cliente
2. Identifique quais informa√ß√µes voc√™ precisa para resolver adequadamente
3. Fa√ßa APENAS as perguntas necess√°rias para obter essas informa√ß√µes
4. Somente ap√≥s a resposta do cliente, forne√ßa a solu√ß√£o espec√≠fica

Diretrizes para respostas:
- Seja amig√°vel, conversacional e natural como um atendente humano
- Adapte seu tom e linguagem de forma personalizada para cada cliente
- Use um portugu√™s brasileiro coloquial e caloroso
- Seja prestativo, mas casual - como uma conversa real com um profissional amig√°vel
- Sinta-se livre para usar emojis com modera√ß√£o para transmitir empatia

Para perguntas sobre treinos e exerc√≠cios:
- Pergunte primeiro sobre objetivos, n√≠vel de condicionamento ou limita√ß√µes antes de sugerir exerc√≠cios
- Ofere√ßa sugest√µes personalizadas baseadas nas respostas
- Recomende treinos da Queima Di√°ria quando relevante, mas sem for√ßar

Para quest√µes de suporte:
- Pergunte primeiro detalhes espec√≠ficos (dispositivo, m√©todo de compra, etc.) antes de oferecer solu√ß√µes
- Priorize resolver o problema do cliente de forma eficiente
- Mantenha um tom emp√°tico mesmo diante de reclama√ß√µes

Inicie suas respostas de forma variada e natural, como:
- "Ol√°! Que bom falar com voc√™..."
- "Oi! Tudo certo? Sou da equipe Queima Di√°ria e..."
- "E a√≠, como vai? Estou aqui para te ajudar..."

Para problemas relatados:
- Pergunte primeiro para entender o contexto espec√≠fico 
- Trate cada caso como √∫nico e n√£o como um padr√£o

Conclua suas mensagens incentivando o cliente a fornecer as informa√ß√µes solicitadas para que voc√™ possa ajudar melhor.
"""

    conversation_context = ""
    if conversation_history and len(conversation_history) > 0:
        conversation_context = "Hist√≥rico recente da conversa para contexto:\n"
        recent_messages = conversation_history[-5:]
        for message in recent_messages:
            role = "Cliente" if message.get('role') == 'user' else "Assistente"
            conversation_context += f"{role}: {message.get('content')}\n"
        conversation_context += "\n"

    full_prompt = f"""{system_prompt}

{conversation_context}
O cliente acabou de dizer: "{question}"

Agora responda como parte da equipe Queima Di√°ria:
- Seja direto, objetivo e emp√°tico
- Fale como um humano que trabalha aqui
- D√™ uma resposta pr√°tica
- Nunca descreva, sempre recomende
"""
    return full_prompt

def save_message_to_dynamodb(session_id, message, role):
    try:
        timestamp = datetime.now().isoformat()
        message_id = str(uuid.uuid4())
        
        item = {
            'session_id': session_id,
            'message_id': message_id,
            'role': role,
            'content': message,
            'timestamp': timestamp
        }
        
        conversation_table.put_item(Item=item)
        return True
    except Exception as e:
        print(f"Erro ao salvar mensagem no DynamoDB: {str(e)}")
        return False

# Fun√ß√£o para recuperar hist√≥rico de conversa do DynamoDB
def get_conversation_history(session_id, limit=10):
    try:
        response = conversation_table.query(
            KeyConditionExpression=boto3.dynamodb.conditions.Key('session_id').eq(session_id),
            ScanIndexForward=True,  # Ordem cronol√≥gica
            Limit=limit
        )
        
        messages = []
        for item in response.get('Items', []):
            messages.append({
                'role': item.get('role'),
                'content': item.get('content'),
                'timestamp': item.get('timestamp')
            })
        
        return messages
    except Exception as e:
        print(f"Erro ao recuperar hist√≥rico de conversa: {str(e)}")
        return []

def retrieveAndGenerate(input_text, kb_id, model_arn, session_id):
    try:
        # Configura√ß√£o para permitir que o modelo use sua base de conhecimento geral
        retrieval_config = {
            'type': 'KNOWLEDGE_BASE',
            'knowledgeBaseConfiguration': {
                'knowledgeBaseId': kb_id,
                'modelArn': model_arn,
                'retrievalConfiguration': {
                    'vectorSearchConfiguration': {
                        'numberOfResults': 5,
                        'overrideSearchType': 'HYBRID'
                    }
                },
                'generationConfiguration': {
                    'inferenceConfig': {
                        'textInferenceConfig': {
                            'temperature': 0.1,
                            'topP': 0.3,
                            'maxTokens': 512,
                        }
                    }
                }
            }
        }
        
        # S√≥ inclua sessionId se for um valor v√°lido
        if session_id and isinstance(session_id, str) and session_id.strip():
            response = bedrock_agent_runtime_client.retrieve_and_generate(
                input={'text': input_text},
                retrieveAndGenerateConfiguration=retrieval_config,
                sessionId=session_id
            )
        else:
            # Para a primeira intera√ß√£o, n√£o envie sessionId
            response = bedrock_agent_runtime_client.retrieve_and_generate(
                input={'text': input_text},
                retrieveAndGenerateConfiguration=retrieval_config
            )
        return response
    except Exception as e:
        print("Error during retrieve_and_generate:", str(e))
        raise

def lambda_handler(event, context):
    print("Event received:", event)
    try:
        # Parsing do corpo da requisi√ß√£o
        if isinstance(event.get('body'), str):
            body = json.loads(event.get('body', '{}'))
        else:
            body = event.get('body', {})
        
        # Extrair a pergunta do body
        question = body.get('question', '')
        
        # Valida√ß√µes iniciais
        if not question.strip():
            return {
                'statusCode': 400,
                'headers': {
                    'Content-Type': 'application/json',
                    'Access-Control-Allow-Origin': '*'
                },
                'body': json.dumps({
                    'error': 'A pergunta (question) √© obrigat√≥ria.'
                })
            }

        # Extra√ß√£o dos par√¢metros
        session_id = body.get('sessionId', "")
        
        # Se session_id n√£o for v√°lido ou estiver vazio, crie um novo
        if not session_id or not session_id.strip():
            session_id = str(uuid.uuid4())
            is_new_session = True
        else:
            is_new_session = False
            
        # Recuperar hist√≥rico de conversa se houver session_id e n√£o for uma nova sess√£o
        conversation_history = []
        if not is_new_session:
            conversation_history = get_conversation_history(session_id)
            
        # Salvar a pergunta do usu√°rio no DynamoDB
        save_message_to_dynamodb(session_id, question, 'user')
        
        # Gerar o prompt com base na pergunta e hist√≥rico
        prompt = generate_prompt(question, conversation_history)
        
        # Chamando a fun√ß√£o para consultar a base de conhecimento
        # N√£o envie session_id para a primeira intera√ß√£o de uma nova sess√£o
        if is_new_session:
            response = retrieveAndGenerate(prompt, kb_id, model_arn, None)
            # Obtenha o session_id da resposta ap√≥s a primeira chamada
            session_id = response.get('sessionId', session_id)
        else:
            response = retrieveAndGenerate(prompt, kb_id, model_arn, session_id)
        
        # Extraindo os dados da resposta
        generated_text = response.get('output', {}).get('text', 'Resposta n√£o encontrada.')
        citations = response.get('citations', [])[:3]  # Limitando a 3 cita√ß√µes
        
        # Salvar a resposta do assistente no DynamoDB
        save_message_to_dynamodb(session_id, generated_text, 'assistant')

        # Retornando a resposta formatada
        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({
                'question': question,
                'answer': generated_text.strip(),
                'sessionId': session_id,
                'citations': [citation.get('retrievedReferences', [{}])[0].get('content', {}).get('text', '') for citation in citations if citation.get('retrievedReferences')]
            })
        }
        
    except Exception as e:
        print("Error in lambda_handler:", str(e))
        return {
            'statusCode': 500,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({
                'error': 'Erro interno ao processar a solicita√ß√£o.',
                'details': str(e)
            })
        }