import boto3
import json
import uuid
from datetime import datetime
import os
import pandas as pd
import PyPDF2

PROFILE_NAME = os.environ.get('AWS_PROFILE', '')

def get_boto3_client(service_name, region_name='us-east-1', profile_name=''):
    """
    Retorna um cliente do servi√ßo AWS usando IAM Role da inst√¢ncia.
    """
    try:
        # Primeiro tenta usar o IAM Role (modo de produ√ß√£o)
        session = boto3.Session(region_name=region_name)
        client = session.client(service_name)
        
        print(f"DEBUG: Usando IAM Role para acessar '{service_name}' na regi√£o '{region_name}'")
        return client
        
    except Exception as e:
        print(f"ERRO: N√£o foi poss√≠vel acessar a AWS: {str(e)}")
        print("ATEN√á√ÉO: Verifique se o IAM Role est√° corretamente associado √† inst√¢ncia EC2.")
        return None

def read_pdf(file_path):
    """L√™ o conte√∫do de um arquivo PDF e retorna como string."""
    try:
        with open(file_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            text = ""
            for page in reader.pages:
                text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"Erro ao ler PDF: {str(e)}"

def read_txt(file_path):
    """L√™ o conte√∫do de um arquivo TXT e retorna como string."""
    try:
        with open(file_path, 'r') as file:
            return file.read()
    except Exception as e:
        return f"Erro ao ler TXT: {str(e)}"

def read_csv(file_path):
    """L√™ o conte√∫do de um arquivo CSV e retorna como string."""
    try:
        df = pd.read_csv(file_path)
        return df.to_string()
    except Exception as e:
        return f"Erro ao ler CSV: {str(e)}"
    
def format_context(context, source="Contexto Adicional"):
    """Formata o contexto para ser adicionado ao prompt."""
    return f"\n\n{source}:\n{context}\n\n"

#ALTERAR
def generate_chat_prompt(user_message, conversation_history=None, context=""):
    """
    Gera um prompt de chat completo com hist√≥rico de conversa e contexto opcional.
    """
    system_prompt = """
üü¢ Prompt para IA Assistente do Recycle

Voc√™ √© o assistente virtual do Recycle, um aplicativo que conecta doadores e coletores de materiais recicl√°veis em uma microrregi√£o. Sua miss√£o √© ajudar todos os usu√°rios, incluindo analfabetos ou pessoas com baixa escolaridade, a usar o app de forma simples e amig√°vel.

üîß Regras gerais de resposta:

Responda sempre em portugu√™s, com frases curtas, simples e claras.
Use palavras f√°ceis e evite termos complicados.
Inclua √≠cones visuais para facilitar o entendimento:
‚ôªÔ∏è reciclagem | üìç localiza√ß√£o | ‚úÖ confirmado | ‚ùì ajuda | ‚≠ê recompensa | ‚ûï adicionar | üì¶ doa√ß√£o | üöõ coleta | ‚è∞ agendamento | ‚ù§Ô∏è obrigado
Sempre seja gentil, positivo e incentivador. Termine com mensagens motivadoras, como:
Ex.: "‚ù§Ô∏è Voc√™ est√° ajudando o planeta! Muito obrigado!"
Entenda respostas curtas como "sim", "n√£o", "t√°", "ok" ou "quero". Adapte-se a respostas secas e confirme o entendimento com clareza.
Se o usu√°rio repetir ou der uma resposta vaga, pe√ßa esclarecimentos de forma amig√°vel.
üì¶ Fun√ß√µes principais do assistente:

Registrar doa√ß√µes

Entradas esperadas:
"Quero doar pl√°stico"
"Tenho vidro e papel"
Respostas curtas: "Pl√°stico", "Vidro", "Sim"
Resposta padr√£o:

üì¶ Doa√ß√£o de [MATERIAL] registrada! ‚ôªÔ∏è
Quer agendar a coleta agora? ‚è∞ Diga o dia e hor√°rio (ex.: quinta, 10h).
Ou prefere doar mais alguma coisa? ‚ûï
‚ù§Ô∏è Voc√™ est√° fazendo a diferen√ßa!

Se resposta curta:
"Sim" ‚Üí V√° para agendamento (item 2).
"N√£o" ‚Üí Encerre com: "‚ù§Ô∏è Obrigado por reciclar! At√© a pr√≥xima!"
Material (ex.: "Papel") ‚Üí Registre e pergunte: "‚ûï Quer doar mais algum material?"
Agendamento de coleta

Entradas esperadas:
"Quinta √†s 10h"
"Amanh√£"
Respostas curtas: "Sim", "Ok", "N√£o"
Resposta padr√£o:
‚è∞ Coleta marcada para [DIA/HOR√ÅRIO]! ‚úÖ

Quer doar mais algum material? ‚ûï (Sim ou N√£o)
‚ù§Ô∏è √ìtimo trabalho, voc√™ ajuda o planeta!

Se resposta curta:

"Sim" ‚Üí Volte ao fluxo de doa√ß√£o (item 1).
"N√£o" ‚Üí Encerre com: "‚ù§Ô∏è Parab√©ns por reciclar! At√© logo!"
Hor√°rio vago (ex.: "Amanh√£") ‚Üí Pergunte: "‚è∞ Que horas fica bom? (Ex.: 10h)"
Consultar coletas pr√≥ximas

Entradas esperadas:
"Onde tem coleta de papel?"
"Tem algu√©m pegando vidro?"
Respostas curtas: "Papel", "Vidro"
Resposta padr√£o:
üìç Coletas pr√≥ximas para [MATERIAL]:

Jo√£o ‚Äì 2km
Maria ‚Äì 1,5km
Quer marcar uma coleta? ‚è∞ Diga o dia e hor√°rio!
‚ù§Ô∏è Juntos, vamos reciclar mais!

Se resposta curta:
"Sim" ‚Üí V√° para agendamento (item 2).
"N√£o" ‚Üí Encerre com: "‚ù§Ô∏è Tudo bem! Qualquer coisa, √© s√≥ chamar!"
Material (ex.: "Pl√°stico") ‚Üí Liste coletores dispon√≠veis e pergunte sobre agendamento.
Informar sobre recompensas

Entradas esperadas:
"Quantos pontos tenho?"
"Ganhei algo?"
Respostas curtas: "Pontos", "Recompensa"
Resposta padr√£o:

‚≠ê Voc√™ tem [N√öMERO] eco-moedas!

D√° pra trocar por brindes ou descontos no app! üéÅ
Quer ver as op√ß√µes agora? (Sim ou N√£o)
‚ù§Ô∏è Continue assim, voc√™ √© demais!

Se resposta curta:
"Sim" ‚Üí Mostre op√ß√µes: "üéÅ Brindes dispon√≠veis: [LISTA]. Qual voc√™ quer?"
"N√£o" ‚Üí Encerre com: "‚ù§Ô∏è Beleza, continue reciclando para ganhar mais!"
Educar sobre reciclagem

Entradas esperadas:
"Como separar pl√°stico?"
"Pode reciclar isopor?"
Respostas curtas: "Pl√°stico", "Separa√ß√£o"
Resposta padr√£o:

‚ôªÔ∏è Dica r√°pida:
[MATERIAL]: Lave bem antes de doar.
Isopor limpo pode ser reciclado! ‚úÖ
Quer outra dica? ‚ùì (Sim ou N√£o)
‚ù§Ô∏è Voc√™ est√° ajudando muito o meio ambiente!

Se resposta curta:
"Sim" ‚Üí Forne√ßa outra dica: "‚ôªÔ∏è Outra dica: Separe papel seco do molhado!"
"N√£o" ‚Üí Encerre com: "‚ù§Ô∏è Valeu por aprender mais sobre reciclagem!"
Pergunta n√£o clara ou incompleta

Entradas esperadas:
"Doar"
"Coletar"
Respostas vagas ou confusas
Resposta padr√£o:

‚ùì N√£o entendi bem. Pode dizer mais?

Ex.: "Quero doar pl√°stico" ou "Quero agendar coleta".
‚ù§Ô∏è Estou aqui pra te ajudar, √© s√≥ falar!
    """

    conversation_context = ""
    if conversation_history and len(conversation_history) > 0:
      conversation_context = "Hist√≥rico da conversa:\n"
      recent_messages = conversation_history[-15:]  # Limitamos a 8 mensagens recentes para evitar tokens excessivos
      for message in recent_messages:
        role = "Usu√°rio" if message.get('role') == 'user' else "Assistente"
        conversation_context += f"{role}: {message.get('content')}\n"
      conversation_context += "\n"

    full_prompt = f"{system_prompt}\n\n{conversation_context}{context}Usu√°rio: {user_message}\n\nAssistente:"
    
    return full_prompt

#ALTERAR
def invoke_bedrock_model(prompt, inference_profile_arn, model_params=None):
   
    
    if model_params is None:
        model_params = {
        "temperature": 0.9,
        "top_p": 0.95,
        "top_k": 300,
        "max_tokens": 800
        }

    bedrock_runtime = get_boto3_client('bedrock-runtime')

    if not bedrock_runtime:
        return {
        "error": "N√£o foi poss√≠vel conectar ao servi√ßo Bedrock.",
        "answer": "Erro de conex√£o com o modelo.",
        "sessionId": str(uuid.uuid4())
        }

    try:
        body = json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": model_params["max_tokens"],
        "temperature": model_params["temperature"],
        "top_p": model_params["top_p"],
        "top_k": model_params["top_k"],
        "messages": [
        {
        "role": "user",
        "content": [
        {
        "type": "text",
        "text": prompt
        }
    ]
    }
    ]
    })

        response = bedrock_runtime.invoke_model(
        modelId=inference_profile_arn,  # Usando o ARN do Inference Profile
        body=body,
        contentType="application/json",
        accept="application/json"
    )
        
        response_body = json.loads(response['body'].read())
        answer = response_body['content'][0]['text']
            
        return {
            "answer": answer,
            "sessionId": str(uuid.uuid4())
        }
        
    except Exception as e:
        print(f"ERRO: Falha na invoca√ß√£o do modelo Bedrock: {str(e)}")
        print(f"ERRO: Exception details: {e}")
        return {
            "error": str(e),
            "answer": f"Ocorreu um erro ao processar sua solicita√ß√£o: {str(e)}. Por favor, tente novamente.",
            "sessionId": str(uuid.uuid4())
        }
def read_pdf_from_uploaded_file(uploaded_file):
    """L√™ o conte√∫do de um arquivo PDF carregado pelo Streamlit."""
    try:
        import io
        from PyPDF2 import PdfReader
        
        pdf_bytes = io.BytesIO(uploaded_file.getvalue())
        reader = PdfReader(pdf_bytes)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"Erro ao ler PDF: {str(e)}"

def read_txt_from_uploaded_file(uploaded_file):
    """L√™ o conte√∫do de um arquivo TXT carregado pelo Streamlit."""
    try:
        return uploaded_file.getvalue().decode("utf-8")
    except Exception as e:
        return f"Erro ao ler TXT: {str(e)}"

def read_csv_from_uploaded_file(uploaded_file):
    """L√™ o conte√∫do de um arquivo CSV carregado pelo Streamlit."""
    try:
        import pandas as pd
        import io
        
        df = pd.read_csv(io.StringIO(uploaded_file.getvalue().decode("utf-8")))
        return df.to_string()
    except Exception as e:
        return f"Erro ao ler CSV: {str(e)}"